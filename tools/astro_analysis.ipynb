{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a816e837-ca3b-43a3-ae74-3c556eb15be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy import units,constants\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import simpson\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from pyaxi_utils import load_single_result, get_kvals, get_times, n_p, n_k\n",
    "\n",
    "output_dir='~/projects/pyAxiverse/data/piaxiverse_main1_SU3'  # Path to folder where subfolders/data files are saved\n",
    "\n",
    "# example file: smooth resonance\n",
    "file_smooth = 'piaxiverse_GMR_L4scan2_SU3_ac8fcc3fa093280e6916ba0d3e17f74a7ab2e8a2'\n",
    "# example file: narrow resonance\n",
    "file_narrow = 'piaxiverse_GMR_L4scan2_SU3_d9c1797fc0793cbd2a5bd8af36603fef3f1433a8'\n",
    "# example file: steep resonance\n",
    "file_steep  = 'piaxiverse_GMR_L4scan_SU3_211b7a1a8656bedb609b007e1cc8828d3991f3b8'\n",
    "# example file: no resonance\n",
    "file_none   = 'piaxiverse_GMR_L4scan_SU3_af2ee65ed6830a0aba14a1a3748f7ccfe47dcb70'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48827a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resonance_check(t,nk,tmax=None):\n",
    "    lnk = np.log10(nk)\n",
    "    #print(np.all(np.isfinite(lnk)))\n",
    "    if np.any(np.isinf(np.abs([nk[0],nk[1]]))):\n",
    "        return 1e99,0.0,[1e99],[0.0]\n",
    "    if np.all(lnk == -np.inf):\n",
    "        return 0.0,t,np.zeros_like(t),t\n",
    "    elif np.all(lnk == np.inf):\n",
    "        return 1e99,0.0,[1e99],[0.0]\n",
    "    elif np.all(np.logical_not(np.isfinite(lnk))):\n",
    "        if len(t[lnk>-np.inf]) <= 0:\n",
    "            tmin = t[0]\n",
    "        else:\n",
    "            tmin = t[lnk>-np.inf][0]\n",
    "        return 1e99,t[lnk==-np.inf], [1e99], [tmin]\n",
    "\n",
    "    n_t = t[np.abs(lnk) < np.inf]\n",
    "    lnk = lnk[np.abs(lnk) < np.inf]\n",
    "    if len(lnk) < 2:\n",
    "        return lnk[0],np.zeros_like(n_t), lnk, n_t\n",
    "    elif len(lnk) < 200:\n",
    "        nk_intp = interp1d(n_t,lnk)\n",
    "        n_t = np.linspace(n_t[0], n_t[-1], num=200)\n",
    "        lnk = nk_intp(n_t)\n",
    "    \n",
    "    if tmax is None:\n",
    "        tmax = np.max(n_t)\n",
    "    filt = gaussian_filter1d(lnk, 1.0) \n",
    "    grad = np.gradient(filt, n_t)\n",
    "    mu_norm = np.array(grad*n_t)\n",
    "    #print('-------')\n",
    "    #print(tmax)\n",
    "    #print(np.where(n_t<=tmax))\n",
    "    #print(n_t)\n",
    "    if len(np.where(n_t<=tmax)) < 0:\n",
    "        mu_max = []\n",
    "        stable_islands = []\n",
    "    else:\n",
    "        try:\n",
    "            mu_max = np.max(mu_norm[np.where(n_t<=tmax)])\n",
    "        except ValueError:\n",
    "            mu_max = np.max(mu_norm)\n",
    "        stable_islands = n_t[np.where(mu_norm < 1)]\n",
    "    return mu_max,stable_islands,mu_norm,n_t\n",
    "\n",
    "def stable_cont(islands,dt):\n",
    "    diff = np.round(np.diff(islands),6)\n",
    "    dt = np.round(dt,6)\n",
    "    idx = np.where(diff != dt)[0]\n",
    "    u = np.insert(islands[idx],len(islands[idx]),islands[-1])\n",
    "    l = np.insert(islands[idx+1],0,islands[0])\n",
    "    return l+dt,u+dt\n",
    "\n",
    "def process_dict(d,exclude=None,exclude_recurse=False):\n",
    "    new_d = {}\n",
    "    if exclude_recurse:\n",
    "        r_ex = exclude\n",
    "    else:\n",
    "        r_ex = None\n",
    "    for key,value in d.items():\n",
    "        if isinstance(value,dict):\n",
    "            new_d[key] = process_dict(value,r_ex)\n",
    "        else:\n",
    "            try:\n",
    "                new_d[key] = np.array(value).tolist()\n",
    "            except:\n",
    "                if isinstance(value,np.generic):\n",
    "                    new_d[key] = value.item()\n",
    "                else:\n",
    "                    new_d[key] = value\n",
    "    if not exclude is None:\n",
    "        for x in exclude:\n",
    "            if x in new_d.keys():\n",
    "                new_d.pop(x)\n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87479b6e-b827-4259-adad-d8bf0be640e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_run(params,data):\n",
    "\n",
    "    # Convert amplitudes to occupation numbers\n",
    "    k_values = get_kvals(params, None)\n",
    "    times    = get_times(params, None)\n",
    "\n",
    "\n",
    "    # 2D dimensionality array || dims = [N_k, N_t]\n",
    "    # Each row contains a list of the occupation numbers over each timestep, for a given k-mode\n",
    "    nk_sep = np.array([n_p(k_i, params, data, k_values, times, n=n_k) for k_i, k_v in enumerate(k_values)])\n",
    "    # 1D array of the total occupation number over each timestep || dims = [N_t]\n",
    "    # Each row contains a list of the occupation number over each timestep, for a given k-mode\n",
    "    nk_tot = np.sum(nk_sep, axis=0)\n",
    "\n",
    "    mu_max,stable_islands,mu_norm,ntimes = resonance_check(times,nk_tot)\n",
    "    mu_norm = np.array(mu_norm)\n",
    "    if len(mu_norm) > 2:\n",
    "        dt = ntimes[1] - ntimes[0]\n",
    "        if len(stable_islands) > 0:\n",
    "            bins_l,bins_u = stable_cont(stable_islands,dt)\n",
    "        else:\n",
    "            bins_l = []\n",
    "        # print(nk_tot)\n",
    "        # plt.plot(times,nk_tot)\n",
    "        # plt.yscale('log')\n",
    "        # plt.show()\n",
    "        if len(bins_l) > 1:\n",
    "            spectrum_criteria = (bins_l[1:]/bins_u[:-1])/1.12\n",
    "            if spectrum_criteria[0] > 1:\n",
    "                r_spec = [bins_u[0]]\n",
    "            else:\n",
    "                try:\n",
    "                    idx = np.where(spectrum_criteria>1)[0][0]\n",
    "                except:\n",
    "                    idx = -1\n",
    "                r_spec = (bins_u[:idx])\n",
    "        elif mu_max >= 1.0:\n",
    "            r_spec = [ntimes[np.where(mu_norm>=1)[0][0]]]\n",
    "    elif mu_max >= 1.0:\n",
    "        r_spec = [ntimes[np.where(mu_norm>=1)[0][0]]]\n",
    "    else:\n",
    "       r_spec = [0]\n",
    "\n",
    "    # plt.plot(ntimes,mu_norm)\n",
    "    # plt.yscale(\"log\")\n",
    "    # plt.show()\n",
    "    m_pi = params['m'][0][0]\n",
    "\n",
    "    if np.any(mu_norm > 1):\n",
    "        resonance = True\n",
    "    else:\n",
    "        resonance = False\n",
    "\n",
    "    if resonance:\n",
    "        tmin = ntimes[np.where(mu_norm>=1)[0][0]]\n",
    "        res_list = []\n",
    "        max_list = []\n",
    "        nk_list = []\n",
    "        for k,nk in zip(k_values,nk_sep):\n",
    "            mu_max_k, stable_k, mu_norm_k, t_k = resonance_check(times, nk, tmax=1.12*tmin)\n",
    "            if mu_max_k > 1:\n",
    "                res_list.append(k)\n",
    "            max_list.append(mu_max_k)\n",
    "            nk_list.append(np.max(nk[times<=1.12*r_spec[0]]))\n",
    "        if not np.all(mu_norm == 1e99):\n",
    "            spec = np.array(max_list)*k_values*nk_list\n",
    "            #plt.plot((k_values*m_pi*units.eV/constants.h).to('MHz').value,spec)\n",
    "\n",
    "            if len(k_values[np.where(spec==np.max(spec))]) > 0:\n",
    "                peak_k = k_values[np.where(spec==np.max(spec))][0] \n",
    "            else:\n",
    "                peak_k = 0.0\n",
    "\n",
    "            intp = interp1d(k_values,spec)\n",
    "            k_int = np.logspace(np.log10(k_values[0]),np.log10(k_values[-1]),num=200)\n",
    "            spec = intp(k_int)\n",
    "            n_spec = [k_int,spec] #[np.where(np.isfinite(spec))]\n",
    "            # plt.plot(k_values,max_list)\n",
    "            # plt.show()\n",
    "        else:\n",
    "            peak_k = 0.0\n",
    "            n_spec = [0.0,0.0]\n",
    "            r_spec = [0.0]\n",
    "    else:\n",
    "        tmin = 0\n",
    "        peak_k = 0\n",
    "        mu_max = 0.0\n",
    "        r_spec = [0.0]\n",
    "        n_spec = [0.0,0.0]\n",
    "    # print(f\"Minimum size = {(tmin/m_pi/(1*units.eV)*constants.h*constants.c).to('km'):.2e}\")\n",
    "    # print(f\"Peak frequency = {(peak_k*m_pi*units.eV/constants.h).to('MHz'):.2e}\")\n",
    "    # print(f\"Bandwidth = {(fwhm*m_pi*units.eV/constants.h).to('MHz'):.2e}\")\n",
    "\n",
    "    out_dict = {}\n",
    "    out_dict['F'] = params['F']\n",
    "    out_dict['m_pi'] = m_pi\n",
    "    out_dict['L4'] = params['L4']\n",
    "    out_dict['p_t'] = params['p_t']\n",
    "    out_dict['rmax'] = (tmin/m_pi/(1*units.eV)*constants.h*constants.c).to('km').value\n",
    "    out_dict['peak_nu'] = (peak_k*m_pi*units.eV/constants.h).to('MHz').value\n",
    "    out_dict['mu_max'] = mu_max\n",
    "    out_dict['rmax_spectrum'] = (np.array(r_spec)/m_pi/(1*units.eV)*constants.h*constants.c).to('km').value\n",
    "    out_dict['n_spectrum'] = [(n_spec[0]*m_pi*units.eV/constants.h).to('MHz').value,n_spec[1]]\n",
    "    # if np.array(n_spec).size > 2:\n",
    "    #     plt.plot(n_spec[0],n_spec[1])\n",
    "    #     plt.yscale('log')\n",
    "    #     plt.show()\n",
    "    return out_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4beecf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cchardet\n",
    "from json import JSONDecodeError\n",
    "from pickle import UnpicklingError\n",
    "\n",
    "def detect_bom(filename, verbosity=0):\n",
    "    with open(filename, 'rb') as f:\n",
    "            if verbosity >= 2:\n",
    "                print('   BOM: ', f.read(4))\n",
    "            raw = f.read(4)\n",
    "            if raw.startswith(b'\\xef\\xbb\\xbf'):\n",
    "                return 'UTF-8'\n",
    "            elif raw.startswith(b'\\xff\\xfe'):\n",
    "                return 'UTF-16 LE'\n",
    "            elif raw.startswith(b'\\xfe\\xff'):\n",
    "                return 'UTF-16 BE'\n",
    "    # Check for UTF-32\n",
    "    try:\n",
    "        with open(filename, encoding='utf-32') as f:\n",
    "            content = f.read()\n",
    "            return 'UTF-32'\n",
    "    except UnicodeDecodeError:\n",
    "        return None\n",
    "\n",
    "def detect_encoding(filename, verbosity=0):\n",
    "    file_bom = detect_bom(filename, verbosity)\n",
    "    if file_bom is not None:\n",
    "        return file_bom\n",
    "    else:\n",
    "        with open(filename, 'rb') as f:\n",
    "            rawdata = f.read()\n",
    "        result = cchardet.detect(rawdata)\n",
    "        return result['encoding']\n",
    "\n",
    "def print_encoding(file_base, ext_list=[''], verbosity=1):\n",
    "    in_file_arr = [file_base+ext for ext in ext_list]\n",
    "    for subfile in in_file_arr:\n",
    "        if verbosity >= 1:\n",
    "            print('   Filename: ', subfile)\n",
    "        print('   Encoding: ', detect_encoding(subfile, verbosity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66928156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1194411/3820884521.py:2: RuntimeWarning: invalid value encountered in log10\n",
      "  lnk = np.log10(nk)\n",
      "/tmp/ipykernel_1194411/3820884521.py:2: RuntimeWarning: divide by zero encountered in log10\n",
      "  lnk = np.log10(nk)\n",
      "/projects/illinois/eng/physics/nyunes/loane2/pyAxiverse/tools/../pyaxi_utils.py:1062: RuntimeWarning: overflow encountered in square\n",
      "  n_k = lambda k, A, Adot, Im: ((k/2)*(np.abs(A)**2 + (np.abs(Adot)**2 / k**2)) - (1/2))\n",
      "/projects/illinois/eng/physics/nyunes/loane2/pyAxiverse/tools/../pyaxi_utils.py:1062: RuntimeWarning: overflow encountered in multiply\n",
      "  n_k = lambda k, A, Adot, Im: ((k/2)*(np.abs(A)**2 + (np.abs(Adot)**2 / k**2)) - (1/2))\n"
     ]
    }
   ],
   "source": [
    "dict_list = []\n",
    "if False:\n",
    "    is_multiple_run_folder = True\n",
    "    in_list_dir = output_dir\n",
    "    in_list = [file_smooth, file_narrow, file_none, file_steep]\n",
    "else:\n",
    "    is_multiple_run_folder = False\n",
    "    in_list_dir = output_dir\n",
    "    in_list = list(set([os.path.splitext(in_file.name)[0].split('_funcs')[0].split('_plots')[0] for in_file in os.scandir(os.path.expanduser(in_list_dir)) if in_file.is_file()]))\n",
    "    skip_list = []\n",
    "    in_list = [filename for filename in in_list if not filename in skip_list]\n",
    "#print('\\n'.join(in_list[:5]))\n",
    "print('---------------------------------')\n",
    "\n",
    "skipped_list = []\n",
    "missing_list = []\n",
    "jsonerr_list = []\n",
    "pickled_list = []\n",
    "n_total = 0\n",
    "n_saved = 0\n",
    "for in_file in in_list:\n",
    "    n_total += 1\n",
    "    if is_multiple_run_folder:\n",
    "        subfolder = '_'.join(in_file.split('_')[:-1])+'/'\n",
    "    else:\n",
    "        subfolder = ''\n",
    "    in_folder = os.path.expanduser(os.path.join(output_dir,subfolder))\n",
    "    \n",
    "    #print(in_file)\n",
    "    #print_encoding(os.path.join(in_folder, in_file))\n",
    "\n",
    "    try:\n",
    "        example_params, example_results, _, _ = load_single_result(in_folder, in_file)\n",
    "    except FileNotFoundError as file_err:\n",
    "        print('FileNotFoundError: %s' % in_file)\n",
    "        #print(file_err)\n",
    "        #raise file_err\n",
    "        continue\n",
    "    except JSONDecodeError as json_err:\n",
    "        #print('JSONDecodeError: %s' % in_file)\n",
    "\n",
    "        #full_file_path = os.path.join(in_folder, in_file)\n",
    "        #ext_file_path = full_file_path + '.json'\n",
    "        #encoding = print_encoding(ext_file_path)\n",
    "\n",
    "        jsonerr_list.append(in_file)\n",
    "        continue\n",
    "    except UnpicklingError as unpickle_err:\n",
    "        #print('UnpicklingError: %s' % in_file)\n",
    "\n",
    "        #full_file_path = os.path.join(in_folder, in_file)\n",
    "        #ext_file_path = full_file_path + '.npy'\n",
    "        #encoding = print_encoding(ext_file_path)\n",
    "\n",
    "        pickled_list.append(in_file)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        out = analyse_run(example_params, example_results)\n",
    "        dict_list.append(process_dict(out))\n",
    "        n_saved += 1\n",
    "    except ValueError as val_err:\n",
    "        print(val_err)\n",
    "        skipped_list.append(in_file)\n",
    "    except FileNotFoundError as file_err:\n",
    "        missing_list.append(in_file)\n",
    "    \n",
    "    # Save progress every 1000 files loaded in\n",
    "    if n_total % 1000 == 0:\n",
    "        with open('astro_data.yaml','w') as out_file:\n",
    "            yaml.dump(dict_list, out_file)\n",
    "\n",
    "dumpfile = 'astro_data.yaml'\n",
    "with open(dumpfile,'w') as out_file:\n",
    "    yaml.dump(dict_list, out_file)\n",
    "\n",
    "print('---------------------------------')\n",
    "n_skipped = len(skipped_list)\n",
    "n_missing = len(missing_list)\n",
    "n_jsonerr = len(jsonerr_list)\n",
    "n_pickled = len(pickled_list)\n",
    "if n_total > 0:\n",
    "    print('%d total runs loaded from %s' % (n_total, output_dir))\n",
    "if n_saved > 0:\n",
    "    print('%d runs saved to %s' % (n_saved, dumpfile))\n",
    "if n_skipped > 0:\n",
    "    print('ValueError files: %d \\n' % n_skipped, skipped_list)\n",
    "if n_missing > 0:\n",
    "    print('FileNotFoundError files: %d \\n' % n_missing, missing_list)\n",
    "if n_jsonerr > 0:\n",
    "    print('JSONDecodeError files: %d \\n' % n_jsonerr, jsonerr_list)\n",
    "if n_pickled > 0:\n",
    "    print('UnpicklingError files: %d \\n' % n_pickled, pickled_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Copy a random sampling of a dataset into a new folder, for testing purposes\n",
    "def copy_sample_subset(output_dir, N=100, copy_path=None, is_multiple_run_folder=False):\n",
    "\n",
    "    def get_new_file_name(in_file):\n",
    "\n",
    "        if is_multiple_run_folder:\n",
    "            subfolder = '_'.join(in_file.split('_')[:-1])+'/'\n",
    "        else:\n",
    "            subfolder = ''\n",
    "\n",
    "        if copy_path is None:\n",
    "            new_folder = os.path.expanduser(os.path.join(output_dir, subfolder, '..', os.path.basename(output_dir)+f'_sample_{N}'))\n",
    "        else:\n",
    "            new_folder = os.path.expanduser(copy_path)\n",
    "\n",
    "        in_file_base = os.path.basename(in_file)\n",
    "        #print('in_file_base: ', in_file_base)\n",
    "        #print('new_folder: ', new_folder)\n",
    "        new_file = os.path.join(os.path.abspath(new_folder), in_file_base)\n",
    "        #print('           ', new_file)\n",
    "        return new_file\n",
    "\n",
    "    if is_multiple_run_folder:\n",
    "        in_list_dir = output_dir\n",
    "        in_list = [file_smooth, file_narrow, file_none, file_steep]\n",
    "    else:\n",
    "        in_list_dir = output_dir\n",
    "        in_list = list(set([os.path.splitext(in_file.name)[0].split('_funcs')[0].split('_plots')[0] for in_file in os.scandir(os.path.expanduser(in_list_dir)) if in_file.is_file()]))\n",
    "        skip_list = []\n",
    "        in_list = [filename for filename in in_list if not filename in skip_list]\n",
    "    \n",
    "    #print(in_list[0])\n",
    "    #print(get_new_file_name(in_list[0]))\n",
    "\n",
    "    sub_list = random.sample(in_list, k=N)\n",
    "\n",
    "    #print(sub_list)\n",
    "\n",
    "    if True:\n",
    "        for sub_list_file in sub_list:\n",
    "            sub_file_set = glob.glob(os.path.expanduser(os.path.join(in_list_dir, sub_list_file+'*')))\n",
    "            for sub_file_src in sub_file_set:\n",
    "                #print('-------------------------')\n",
    "                sub_file_dst = get_new_file_name(sub_file_src)\n",
    "                #print('Copying : ', sub_file_src)\n",
    "                #print(' ------>  ', sub_file_dst)\n",
    "                sub_file_dst_dir = os.path.abspath(os.path.join(sub_file_dst, '..'))\n",
    "                if not os.path.exists(sub_file_dst_dir):\n",
    "                    os.makedirs(sub_file_dst_dir)\n",
    "                shutil.copy(sub_file_src, sub_file_dst)\n",
    "    \n",
    "    print(f'Done copying files for N={N} runs from {output_dir}')\n",
    "\n",
    "\n",
    "\n",
    "copy_sample_subset(output_dir, N=1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f07fd36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:  100\n",
      "corrupted_set: \n",
      " {'piaxiverse_main1_SU3_71faff269891ec1c3b7f07302fc7fb0c3151da90', 'piaxiverse_main1_SU3_7258003a6607e89b04ca8298994651fc8ad6be34', 'piaxiverse_main1_SU3_714aa17ff2bafc668f059ec92a22f257af31a34a', 'piaxiverse_main1_SU3_72877f0e8a3e1ffee4ddc4d74c0bddde2bbc656f', 'piaxiverse_main1_SU3_72644afeb5051f0922c4ca95d3c1942bacae0100', 'piaxiverse_main1_SU3_724bac79545d10c1e9d07e7df3a2b481d86208ae', 'piaxiverse_main1_SU3_71dc00a550dd7d803a70d2771d33c98c6095e450', 'piaxiverse_main1_SU3_70f67403730e1cf89bfdbe0f5acac5b59cd2405d', 'piaxiverse_main1_SU3_71c5edba3f8bfaea1c442adc8c4a65b356cb081a', 'piaxiverse_main1_SU3_7085b83f7701ef16417364323f0cc172c3a5f1c9', 'piaxiverse_main1_SU3_71d4267421ca07a927153e867517aa9df7a49e27', 'piaxiverse_main1_SU3_71729849d6e1ef16d9a82db6d828d5b2a1c10123', 'piaxiverse_main1_SU3_71ae04506168d725a71adbfea15631da47bf4049', 'piaxiverse_main1_SU3_723f8c8639129446ec81104c7784c29129501afa', 'piaxiverse_main1_SU3_722bad514842426280c44cc46e413e0bcac6d488', 'piaxiverse_main1_SU3_70630a33870cf590f533df14e8b10e515c312f3b', 'piaxiverse_main1_SU3_7192be1c08b97223c2ce6a425ca12e63f325e5be', 'piaxiverse_main1_SU3_708fe32d79b12c67e8d502db45e3c7fe9438e227', 'piaxiverse_main1_SU3_722809084ad6ea1ba8b8debddebf8ad8f82c48fd', 'piaxiverse_main1_SU3_70de2004eab863c9dfdf485c1bf62090e132b370', 'piaxiverse_main1_SU3_717d4725298af9188bd4246448c4fc9f54fe690b', 'piaxiverse_main1_SU3_72752580a364bcd5c84f15e0073136a8a98b9f1d', 'piaxiverse_main1_SU3_721bd8e65b63d4c0078bc82261ab387af62ceb09', 'piaxiverse_main1_SU3_70eef8110936906645cda14583142a77aea024fb', 'piaxiverse_main1_SU3_714d8413a3b19b0c8c230237a897fb980311900d', 'piaxiverse_main1_SU3_71df79d1d2bc8a23e21b7317b715a1d6ec1cc0d1', 'piaxiverse_main1_SU3_723cb1ad05f76ff75887acdb7137547c2f003279', 'piaxiverse_main1_SU3_7101922dcf0b861958cd675266cf4d9100296296', 'piaxiverse_main1_SU3_71b0e77e873a70ea7d563abe46f7e596098b9d66', 'piaxiverse_main1_SU3_712ab01e3f1e077c89f45f4c301b9b7608ca7f1a', 'piaxiverse_main1_SU3_7191d15925ce4b214b8418628d3076c00644e48b', 'piaxiverse_main1_SU3_71d711d096dbb0c14cb0e3fd66f1b4cee83c8a37', 'piaxiverse_main1_SU3_710ef8c70ef1c2b049afdb5f5188152f99261285', 'piaxiverse_main1_SU3_7240d7cc84496bb8c23e656d7c38095ea5684de3', 'piaxiverse_main1_SU3_721e41a7c3eee2f30001f4619480a5e3a4bfcb55', 'piaxiverse_main1_SU3_71e117b2b6f0d3805b081f3cd9cf669d3decd651', 'piaxiverse_main1_SU3_71b60afeb6d2881448449d02662517f81748ba03', 'piaxiverse_main1_SU3_71a7b19061b6fdbed9778f136f9fee37a7ca68fd', 'piaxiverse_main1_SU3_711b1c6bf963d9a84aa46c66d34fa3353e79a114', 'piaxiverse_main1_SU3_71d9343399f94000f6c16a4ad67e95a38f800bcc', 'piaxiverse_main1_SU3_7231545e576e94b636a601341bf3effb599ab524', 'piaxiverse_main1_SU3_717be561183c23a23772badefb3a8618d01624a0', 'piaxiverse_main1_SU3_71b6a73d94cccf232ac4b2ff447cd6a4ec7bdb82', 'piaxiverse_main1_SU3_711b88fb6ca0875db71fc71a39cfb7e3fd52f477', 'piaxiverse_main1_SU3_70b0bd19d6dca78223cb54708fa7e90999dc207c', 'piaxiverse_main1_SU3_726d17407cd83519eddcfe78a473321d560eb7ba', 'piaxiverse_main1_SU3_71a697ef0321bcf17c8531a510abe607ee37a801', 'piaxiverse_main1_SU3_70eff2a12ba3b7ee4eb4bab16120b4c2d1138840', 'piaxiverse_main1_SU3_71b09f5ca5b2898d2426a2fbb6d264013ce0c384', 'piaxiverse_main1_SU3_7180e695dcb97eb0a0dff3e62892087bc720a40e', 'piaxiverse_main1_SU3_7210cb5e6d8b9952bd101f73be48407323a6a1a2', 'piaxiverse_main1_SU3_727211faf29e3b1ca77a1f87ce829eb4b85b62d0', 'piaxiverse_main1_SU3_71478c6d54a26d88c4edfeb3073a761a387740f0', 'piaxiverse_main1_SU3_7041cb772a91a814ebdc8920a485cdf4dac231c4', 'piaxiverse_main1_SU3_727a4d55eca060a748437744174aa08f46f62684', 'piaxiverse_main1_SU3_710c0acf1100f7a3c9d30c00423a18df2fbfaef5', 'piaxiverse_main1_SU3_720c54a4e377f9a01fb71063df3bf6e55d4af9ac', 'piaxiverse_main1_SU3_7180b7135c5a722dfe12fa8d201f7a08ffe4c75b', 'piaxiverse_main1_SU3_7191edc5b6000941b8b9f073193fc173c3f5bfc4', 'piaxiverse_main1_SU3_71c80d8950c68826eccc591fdfa1a4d9175197ab', 'piaxiverse_main1_SU3_718251a87d1a0351520c0b9c34083c45667a21fb', 'piaxiverse_main1_SU3_71b4e87a45aa8e012737dbb58af2740403837aa3', 'piaxiverse_main1_SU3_71f10d63bbcf14056a6ba1dd0a0852e631bc72da', 'piaxiverse_main1_SU3_725a876de15c04fafd0958f52680b714f29f6316', 'piaxiverse_main1_SU3_7245ce6f51f1fd5fe4d05325889d5306096fbe93', 'piaxiverse_main1_SU3_70656251d9420f1f12a7aafd211134aa20f58ef4', 'piaxiverse_main1_SU3_707dcf96556f24aa31091e7fd67470a672aa3e16', 'piaxiverse_main1_SU3_716d34d7c00558994cbef8515977da8f7d5e8f0f', 'piaxiverse_main1_SU3_71075f9b14913fa91ace5cbdff8a9e26378c71b4', 'piaxiverse_main1_SU3_720eb0d0118056dedcb4e103b776200fafa51b70', 'piaxiverse_main1_SU3_7151fab103c9fff3d849e288ff7498c1c790ceb0', 'piaxiverse_main1_SU3_7114111185730c4b516a7e1ded3dd223e33babef', 'piaxiverse_main1_SU3_72411dc856a9e9aaf7e79d5b6e6df751413268bb', 'piaxiverse_main1_SU3_71ec1a208b07cf5e55ddec6884d3c69f156bcd07', 'piaxiverse_main1_SU3_7212300e44fc60b22f51769069d8b6cb8756df91', 'piaxiverse_main1_SU3_71dfe0f7065f09701f0cf04a5f221597c6e8bcdd', 'piaxiverse_main1_SU3_70eec2c283b004a849baffdda036bc9fbd815a40', 'piaxiverse_main1_SU3_72046ec9eac18eee5872dbe50d950ca38e9c267d', 'piaxiverse_main1_SU3_706b93f956b49cf70ae238867ac40bdd3341c0ba', 'piaxiverse_main1_SU3_714bca42dccf303aa16378d7226d0063593a58bd', 'piaxiverse_main1_SU3_714eb24cab5d9ecfe5ca84b927aa159fd146149f', 'piaxiverse_main1_SU3_707798109fd9c550b823f025cc0ee3a7a5913bb3', 'piaxiverse_main1_SU3_7209d540a44fb7bf6036f24087abca513065b998', 'piaxiverse_main1_SU3_7249e8ac6c5064c9ca26939a16b5b0107bd7d250', 'piaxiverse_main1_SU3_71ff705d7c56abf7b82619dd076543fd1b496e41', 'piaxiverse_main1_SU3_715d54149f496c51875a1aed77be15742faed9ff', 'piaxiverse_main1_SU3_71a054b9c61ee763b2741013e80afb230c68248e', 'piaxiverse_main1_SU3_71bebc583faa90f20b456ff01b984997497d8884', 'piaxiverse_main1_SU3_720d15f14f4754b452373d410bf57efa961fd4dd', 'piaxiverse_main1_SU3_71f00455865c899516eb45cfdac095c4b823331e', 'piaxiverse_main1_SU3_72288e4f486fbb6aeab2a4c3445025e1293869b9', 'piaxiverse_main1_SU3_7222fbe6a88b642ba7826817f60e100f974d0a3d', 'piaxiverse_main1_SU3_71ea649f2410862d99a7b8257711ae701d62d9eb', 'piaxiverse_main1_SU3_72511abce45765763b670552cca96ea3e6a36bc3', 'piaxiverse_main1_SU3_71681e1de2f1a63f2f6e480b6e8239f1de9c89af', 'piaxiverse_main1_SU3_714c1b4559c76913e6ee61e17cd68c645a79e3aa', 'piaxiverse_main1_SU3_707eb322d822db968511097de462e8434328a783', 'piaxiverse_main1_SU3_7261dba3aa3caddb363a338bd6855dfcf98a7948', 'piaxiverse_main1_SU3_71a1b56826e071b521670664b48ade7147bca34e', 'piaxiverse_main1_SU3_7063703a6cb8546978b49b4bdc731e8a244c0435'}\n",
      "Deleted 100 files\n"
     ]
    }
   ],
   "source": [
    "# Delete corrupted files\n",
    "delete_corrupted = True\n",
    "if delete_corrupted:\n",
    "    corrupted_set = set(jsonerr_list).union(set(pickled_list))\n",
    "    print('N: ', len(corrupted_set))\n",
    "    print('corrupted_set: \\n', corrupted_set)\n",
    "    if True and len(corrupted_set) > 0:\n",
    "        for file_stub in corrupted_set:\n",
    "            # Specify the pattern for files to delete\n",
    "            del_pattern = os.path.join(in_folder, file_stub+'*')\n",
    "\n",
    "            # Find all matching files\n",
    "            del_files = glob.glob(del_pattern)\n",
    "\n",
    "            # Delete each file\n",
    "            for file in del_files:\n",
    "                os.remove(file)\n",
    "        print(f'Deleted {len(corrupted_set)} files')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyaxiverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
